{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "from scipy import signal\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "pd.set_option('display.max_rows', 600)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from keras.layers import * # Keras is the most friendly Neural Network library, this Kernel use a lot of layers classes\n",
    "from keras.models import Model\n",
    "from keras import backend as K # The backend give us access to tensorflow operations and allow us to create the Attention class\n",
    "from keras import optimizers # Allow us to access the Adam class to modify some parameters\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold # Used to use Kfold to train our model\n",
    "from keras.callbacks import * # This object helps the model to train in a smarter way, avoiding overfitting\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('../input/X_train.csv')\n",
    "y_train = pd.read_csv('../input/y_train.csv')\n",
    "X_test  = pd.read_csv('../input/X_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>series_id</th>\n",
       "      <th>measurement_number</th>\n",
       "      <th>orientation_X</th>\n",
       "      <th>orientation_Y</th>\n",
       "      <th>orientation_Z</th>\n",
       "      <th>orientation_W</th>\n",
       "      <th>angular_velocity_X</th>\n",
       "      <th>angular_velocity_Y</th>\n",
       "      <th>angular_velocity_Z</th>\n",
       "      <th>linear_acceleration_X</th>\n",
       "      <th>linear_acceleration_Y</th>\n",
       "      <th>linear_acceleration_Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.75853</td>\n",
       "      <td>-0.63435</td>\n",
       "      <td>-0.10488</td>\n",
       "      <td>-0.10597</td>\n",
       "      <td>0.107650</td>\n",
       "      <td>0.017561</td>\n",
       "      <td>0.000767</td>\n",
       "      <td>-0.74857</td>\n",
       "      <td>2.1030</td>\n",
       "      <td>-9.7532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.75853</td>\n",
       "      <td>-0.63434</td>\n",
       "      <td>-0.10490</td>\n",
       "      <td>-0.10600</td>\n",
       "      <td>0.067851</td>\n",
       "      <td>0.029939</td>\n",
       "      <td>0.003385</td>\n",
       "      <td>0.33995</td>\n",
       "      <td>1.5064</td>\n",
       "      <td>-9.4128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.75853</td>\n",
       "      <td>-0.63435</td>\n",
       "      <td>-0.10492</td>\n",
       "      <td>-0.10597</td>\n",
       "      <td>0.007275</td>\n",
       "      <td>0.028934</td>\n",
       "      <td>-0.005978</td>\n",
       "      <td>-0.26429</td>\n",
       "      <td>1.5922</td>\n",
       "      <td>-8.7267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.75852</td>\n",
       "      <td>-0.63436</td>\n",
       "      <td>-0.10495</td>\n",
       "      <td>-0.10597</td>\n",
       "      <td>-0.013053</td>\n",
       "      <td>0.019448</td>\n",
       "      <td>-0.008974</td>\n",
       "      <td>0.42684</td>\n",
       "      <td>1.0993</td>\n",
       "      <td>-10.0960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.75852</td>\n",
       "      <td>-0.63435</td>\n",
       "      <td>-0.10495</td>\n",
       "      <td>-0.10596</td>\n",
       "      <td>0.005135</td>\n",
       "      <td>0.007652</td>\n",
       "      <td>0.005245</td>\n",
       "      <td>-0.50969</td>\n",
       "      <td>1.4689</td>\n",
       "      <td>-10.4410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  row_id  series_id  measurement_number  orientation_X  orientation_Y  \\\n",
       "0    0_0          0                   0       -0.75853       -0.63435   \n",
       "1    0_1          0                   1       -0.75853       -0.63434   \n",
       "2    0_2          0                   2       -0.75853       -0.63435   \n",
       "3    0_3          0                   3       -0.75852       -0.63436   \n",
       "4    0_4          0                   4       -0.75852       -0.63435   \n",
       "\n",
       "   orientation_Z  orientation_W  angular_velocity_X  angular_velocity_Y  \\\n",
       "0       -0.10488       -0.10597            0.107650            0.017561   \n",
       "1       -0.10490       -0.10600            0.067851            0.029939   \n",
       "2       -0.10492       -0.10597            0.007275            0.028934   \n",
       "3       -0.10495       -0.10597           -0.013053            0.019448   \n",
       "4       -0.10495       -0.10596            0.005135            0.007652   \n",
       "\n",
       "   angular_velocity_Z  linear_acceleration_X  linear_acceleration_Y  \\\n",
       "0            0.000767               -0.74857                 2.1030   \n",
       "1            0.003385                0.33995                 1.5064   \n",
       "2           -0.005978               -0.26429                 1.5922   \n",
       "3           -0.008974                0.42684                 1.0993   \n",
       "4            0.005245               -0.50969                 1.4689   \n",
       "\n",
       "   linear_acceleration_Z  \n",
       "0                -9.7532  \n",
       "1                -9.4128  \n",
       "2                -8.7267  \n",
       "3               -10.0960  \n",
       "4               -10.4410  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_id</th>\n",
       "      <th>group_id</th>\n",
       "      <th>surface</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>fine_concrete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>concrete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>concrete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>concrete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>soft_tiles</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   series_id  group_id        surface\n",
       "0          0        13  fine_concrete\n",
       "1          1        31       concrete\n",
       "2          2        20       concrete\n",
       "3          3        31       concrete\n",
       "4          4        22     soft_tiles"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = y_train['surface'].value_counts().index\n",
    "print(targets)\n",
    "print(y_train['surface'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_to_id = {}\n",
    "id_to_target = {}\n",
    "\n",
    "for target in targets:\n",
    "    if target not in target_to_id:\n",
    "        new_id = len(target_to_id)\n",
    "        target_to_id[target] = new_id\n",
    "        id_to_target[new_id] = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_id = []\n",
    "for i in range(len(y_train)):\n",
    "    y_id.append(target_to_id[y_train['surface'].values[i]])\n",
    "y_id = np.asarray(y_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_num = len(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_id_one = np.zeros((len(y_id), class_num))\n",
    "for i in range(len(y_id)):\n",
    "    y_id_one[i, y_id[i]] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_quat(df):\n",
    "    norm = (df['orientation_X']**2 + df['orientation_Y']**2 + df['orientation_Z']**2 + df['orientation_W']**2)**0.5\n",
    "    df['orientation_X'] /= norm\n",
    "    df['orientation_Y'] /= norm\n",
    "    df['orientation_Z'] /= norm\n",
    "    df['orientation_W'] /= norm\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def quaternion_to_euler(x, y, z, w):\n",
    "    t0 = +2.0 * (w * x + y * z)\n",
    "    t1 = +1.0 - 2.0 * (x * x + y * y)\n",
    "    X = math.atan2(t0, t1)\n",
    "\n",
    "    t2 = +2.0 * (w * y - z * x)\n",
    "    t2 = +1.0 if t2 > +1.0 else t2\n",
    "    t2 = -1.0 if t2 < -1.0 else t2\n",
    "    Y = math.asin(t2)\n",
    "\n",
    "    t3 = +2.0 * (w * z + x * y)\n",
    "    t4 = +1.0 - 2.0 * (y * y + z * z)\n",
    "    Z = math.atan2(t3, t4)\n",
    "\n",
    "    return X, Y, Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = norm_quat(X_train)\n",
    "X_test = norm_quat(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fe_step1 (df):\n",
    "    \"\"\"Quaternions to Euler Angles\"\"\"\n",
    "    \n",
    "    x = df['orientation_X'].values\n",
    "    y = df['orientation_Y'].values\n",
    "    z = df['orientation_Z'].values\n",
    "    w = df['orientation_W'].values\n",
    "    nx, ny, nz = np.zeros(len(x)), np.zeros(len(y)), np.zeros(len(z)),\n",
    "    for i in tqdm(range(len(x))):\n",
    "        xx, yy, zz = quaternion_to_euler(x[i], y[i], z[i], w[i])\n",
    "        nx[i] = xx\n",
    "        ny[i] = yy\n",
    "        nz[i] = zz\n",
    "    \n",
    "    df['euler_X'] = nx\n",
    "    df['euler_Y'] = ny\n",
    "    df['euler_Z'] = nz\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = fe_step1(X_train)\n",
    "X_test = fe_step1(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in [X_train, X_test]:\n",
    "    data['obs_roll'] = np.arctan(data['linear_acceleration_Y']/data['linear_acceleration_Z'])\n",
    "    data['obs_pitch'] = -np.arctan(data['linear_acceleration_X']/(data['linear_acceleration_Y']**2+data['linear_acceleration_Z']**2)**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['angular_velocity_X', 'angular_velocity_Y', 'angular_velocity_Z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cols:\n",
    "    X_train['cos_'+col] = np.cos(X_train[col])\n",
    "    X_test['cos_'+col] = np.cos(X_test[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highpass_filter(df):\n",
    "    n_samples = 128\n",
    "    sample_duration = 0.01\n",
    "    sample_rate = n_samples * (1 / sample_duration)\n",
    "\n",
    "    nyquist = 0.5 * sample_rate\n",
    "    norm_low_cutoff = 500 / nyquist\n",
    "\n",
    "    sos = signal.butter(10, Wn=[norm_low_cutoff], btype='highpass', output='sos')\n",
    "    filtered_sig = signal.sosfilt(sos, df)\n",
    "    \n",
    "    return filtered_sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowpass_filter(data, r=0.3):\n",
    "    f_data = np.zeros_like(data)\n",
    "    f_data[0] = data[0]\n",
    "    for i in range(1, len(data)):\n",
    "        if i % 128 == 0:\n",
    "            f_data[i] = data[i]\n",
    "        else:\n",
    "            f_data[i] = r * data[i] + (1-r) * f_data[i-1]\n",
    "    return f_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in [X_train, X_test]:\n",
    "    data['linear_acceleration_X'] = lowpass_filter(data['linear_acceleration_X'])\n",
    "    data['linear_acceleration_Y'] = lowpass_filter(data['linear_acceleration_Y'])\n",
    "    data['linear_acceleration_Z'] = lowpass_filter(data['linear_acceleration_Z'])\n",
    "    #data['angular_velocity_X'] = highpass_filter(data['angular_velocity_X'])\n",
    "    #data['angular_velocity_Y'] = highpass_filter(data['angular_velocity_Y'])\n",
    "    #data['angular_velocity_Z'] = highpass_filter(data['angular_velocity_Z'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lagged_feature(df, lag_list):\n",
    "    \n",
    "    cols = ['angular_velocity_X', 'angular_velocity_Y', 'angular_velocity_Z',\n",
    "            'linear_acceleration_X', 'linear_acceleration_Y', 'linear_acceleration_Z']\n",
    "    \n",
    "    for col in cols:\n",
    "        for i in lag_list:\n",
    "            df[col+'-'+str(i)] = 0\n",
    "            df.loc[i: , col+'-'+str(i)] = df.loc[:len(df)-(i+1), col].values\n",
    "            df[col+'-'+col+'-'+str(i)] = df[col] - df[col+'-'+str(i)]\n",
    "            \n",
    "            df = df.drop([col+'-'+str(i)], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_integration(df):\n",
    "    \n",
    "    cols = ['angular_velocity_X', 'angular_velocity_Y', 'angular_velocity_Z',\n",
    "            'linear_acceleration_X', 'linear_acceleration_Y', 'linear_acceleration_Z']\n",
    "    \n",
    "    for col in cols:\n",
    "        i = 1\n",
    "        df[col+'-'+str(i)] = 0\n",
    "        df.loc[i: , col+'-'+str(i)] = df.loc[:len(df)-(i+1), col].values\n",
    "        df['tmp'+col] = 0.5 * (df[col] + df[col+'-'+str(i)])\n",
    "        df['num_int_'+col] = 0\n",
    "        for j in tqdm(range(0, len(df), 128)):\n",
    "            df.loc[j:j+128, 'num_int_'+col] = np.cumsum(df.loc[j:j+128, 'tmp'+col])\n",
    "\n",
    "        df = df.drop([col+'-'+str(i)], axis=1)\n",
    "        df = df.drop(['tmp'+col], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['linear_acceleration_Z'] = X_train['linear_acceleration_Z'] + 9.80665\n",
    "X_test['linear_acceleration_Z'] = X_test['linear_acceleration_Z'] + 9.80665"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_list = [1, 2]\n",
    "X_train = lagged_feature(X_train, lag_list)\n",
    "X_test = lagged_feature(X_test, lag_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = num_integration(X_train)\n",
    "X_test = num_integration(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "plt.plot(X_train.iloc[128*i:128*(i+1), :]['linear_acceleration_Y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i in tqdm(range(0, len(X_train), 128)):\n",
    "    X_train = X_train.drop(index=[i+j for j in range(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_change_of_abs_change(x):\n",
    "        return np.mean(np.diff(np.abs(np.diff(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = X_train.loc[:, 'orientation_X':'orientation_W']\n",
    "test = X_test.loc[:, 'orientation_X':'orientation_W']\n",
    "\n",
    "train.columns = ['X','Y','Z','W']\n",
    "test.columns = ['X','Y','Z','W']\n",
    "\n",
    "for i in range(4):\n",
    "    for j in range(i+1, 4):\n",
    "        train[train.columns[i]+'-'+train.columns[j]] = train.iloc[:, i] - train.iloc[:, j]\n",
    "        test[test.columns[i]+'-'+test.columns[j]] = test.iloc[:, i] - test.iloc[:, j]\n",
    "        \n",
    "train = pd.concat([train, X_train.loc[:, 'euler_X':'obs_pitch']], axis=1)\n",
    "test = pd.concat([test, X_test.loc[:, 'euler_X':'obs_pitch']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in [train, test]:\n",
    "    data['euler_X-Y'] = data['euler_X']-data['euler_Y']\n",
    "    data['euler_X-Z'] = data['euler_X']-data['euler_Z']\n",
    "    data['euler_Y-Z'] = data['euler_Y']-data['euler_Z']\n",
    "    \n",
    "train = pd.concat([X_train['series_id'], train], axis=1)\n",
    "test = pd.concat([X_test['series_id'], test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotation_matrix(q0, q1, q2, q3):\n",
    "    r00 = q0**2 - q1**2 - q2**2 + q3**2\n",
    "    r01 = 2 * (q0*q3 + q1*q2)\n",
    "    r02 = 2 * (q1*q3 - q0*q2)\n",
    "    r10 = 2 * (q1*q2 - q0*q3)\n",
    "    r11 = q0**2 - q1**2 + q2**2 - q3**2\n",
    "    r12 = 2 * (q2*q3 + q0*q1)\n",
    "    r20 = 2 * (q0*q2 + q1*q3)\n",
    "    r21 = 2 * (-q0*q1 + q2*q3)\n",
    "    r22 = q0**2 - q1**2 - q2**2 + q3**2\n",
    "    R = np.array([[r00, r01, r02],[r10, r11, r12],[r20, r21, r22]])\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotated_acceleration(df):\n",
    "    \n",
    "    df['rotated_acceleration_X'] = 0\n",
    "    df['rotated_acceleration_Y'] = 0\n",
    "    df['rotated_acceleration_Z'] = 0\n",
    "    #df['rotated_angvel_X'] = 0\n",
    "    #df['rotated_angvel_Y'] = 0\n",
    "    #df['rotated_angvel_Z'] = 0\n",
    "    \n",
    "    q0_all = df['orientation_X'].values\n",
    "    q1_all = df['orientation_Y'].values\n",
    "    q2_all = df['orientation_Z'].values\n",
    "    q3_all = df['orientation_W'].values\n",
    "    la_X = df['linear_acceleration_X'].values\n",
    "    la_Y = df['linear_acceleration_Y'].values\n",
    "    la_Z = df['linear_acceleration_Z'].values\n",
    "    #av_X = df['angular_velocity_X'].values\n",
    "    #av_Y = df['angular_velocity_Y'].values\n",
    "    #av_Z = df['angular_velocity_Z'].values\n",
    "    \n",
    "    for i in tqdm(range(len(df))):\n",
    "        q0 = q0_all[i]\n",
    "        q1 = q1_all[i]\n",
    "        q2 = q2_all[i]\n",
    "        q3 = q3_all[i]\n",
    "        \n",
    "        R = rotation_matrix(q0, q1, q2, q3)\n",
    "        la = np.array([la_X[i], la_Y[i], la_Z[i]])\n",
    "        #av = np.array([av_X[i], av_Y[i], av_Z[i]])\n",
    "        rotated_la = np.dot(R.T, la)\n",
    "        #rotated_av = np.dot(R.T, av)\n",
    "        \n",
    "        df.loc[i, 'rotated_acceleration_X'] = rotated_la[0]\n",
    "        df.loc[i, 'rotated_acceleration_Y'] = rotated_la[1]\n",
    "        df.loc[i, 'rotated_acceleration_Z'] = rotated_la[2]\n",
    "        #df.loc[i, 'rotated_angvel_X'] = rotated_av[0]\n",
    "        #df.loc[i, 'rotated_angvel_Y'] = rotated_av[1]\n",
    "        #df.loc[i, 'rotated_angvel_Z'] = rotated_av[2]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = rotated_acceleration(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = rotated_acceleration(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['rotated_acceleration_Y'] = X_train['rotated_acceleration_Y'] - 9.80665\n",
    "X_test['rotated_acceleration_Y'] = X_test['rotated_acceleration_Y'] - 9.80665"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def process_subtrain(arg_tuple):\n",
    "    start, end, idx = arg_tuple\n",
    "    X_tr = X_train.iloc[start:end, :]\n",
    "    X_tr = rotated_acceleration(X_tr)\n",
    "    return idx, X_tr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all_chunks = []\n",
    "\n",
    "num_cores = 8 \n",
    "total_size = len(X_train)\n",
    "chunk_size = total_size/num_cores\n",
    "\n",
    "for i in range(8):\n",
    "    start_idx = int(i * chunk_size)\n",
    "    end_idx = int(start_idx + chunk_size)\n",
    "    chunk = (start_idx, end_idx, i)\n",
    "    all_chunks.append(chunk)\n",
    "\n",
    "pool = Pool()\n",
    "results = pool.map(process_subtrain, all_chunks)    \n",
    "results = sorted(results, key=lambda tup: tup[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X = np.concatenate([item[1] for item in results], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train = pd.concat([train, X_train.loc[:, 'rotated_acceleration_X':'rotated_acceleration_Z']], axis=1)\n",
    "test = pd.concat([test, X_test.loc[:, 'rotated_acceleration_X':'rotated_acceleration_Z']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_eng(df):\n",
    "    data = pd.DataFrame()\n",
    "    #df['total_rotated_acce'] = (df['rotated_acceleration_X']**2 + df['rotated_acceleration_Y']**2 + df['rotated_acceleration_Z']**2)**0.5\n",
    "    df['ang_XY'] = np.arctan2(df['X'], df['Y'])\n",
    "    df['ang_ZW'] = np.arctan2(df['Z'], df['W'])\n",
    "    \n",
    "    df_columns = df.columns[1:]\n",
    "    for col in tqdm(df_columns):\n",
    "        data[col + '_mean'] = df.groupby(['series_id'])[col].mean()\n",
    "        #data[col + '_median'] = df.groupby(['series_id'])[col].median()\n",
    "        data[col + '_max'] = df.groupby(['series_id'])[col].max()\n",
    "        data[col + '_min'] = df.groupby(['series_id'])[col].min()\n",
    "        data[col + '_std'] = df.groupby(['series_id'])[col].std()\n",
    "        data[col + '_range'] = data[col + '_max'] - data[col + '_min']\n",
    "        data[col + '_maxtoMin'] = data[col + '_max'] / data[col + '_min']\n",
    "        \n",
    "        data[col + '_mean_abs_chg'] = df.groupby(['series_id'])[col].apply(lambda x: np.mean(np.abs(np.diff(x))))\n",
    "        data[col + '_mean_change_of_abs_change'] = df.groupby('series_id')[col].apply(mean_change_of_abs_change)\n",
    "        data[col + '_abs_max'] = df.groupby(['series_id'])[col].apply(lambda x: np.max(np.abs(x)))\n",
    "        data[col + '_abs_min'] = df.groupby(['series_id'])[col].apply(lambda x: np.min(np.abs(x)))\n",
    "        data[col + '_abs_avg'] = (data[col + '_abs_min'] + data[col + '_abs_max'])/2\n",
    "        \n",
    "        \n",
    "    #data['corr_linZangX'] = np.correlate(np.abs(tmp_df[:, 0]), np.abs(tmp_df[:, 1]))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train, rotated_tr.loc[:, 'rotated_acceleration_X':'rotated_acceleration_Z']], axis=1)\n",
    "test = pd.concat([test, rotated_te.loc[:, 'rotated_acceleration_X':'rotated_acceleration_Z']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train = feat_eng(train)\n",
    "test = feat_eng(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_col = train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in [train, test]:\n",
    "    data.fillna(0,inplace=True)\n",
    "    data.replace(-np.inf,0,inplace=True)\n",
    "    data.replace(np.inf,0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_gr = y_train['group_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N_SPLITS=4\n",
    "\n",
    "splits = list(StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=2019).split(train, y_gr))\n",
    "\n",
    "clf = []\n",
    "val_acc = []\n",
    "val_pred = []\n",
    "val_y = []\n",
    "\n",
    "lgb_params = {\n",
    "               'feature_fraction': 0.8,\n",
    "               'metric': 'multi_logloss',\n",
    "               'nthread':8, \n",
    "               'learning_rate': 0.1, \n",
    "               'objective': 'multiclass',\n",
    "               'num_class': 73,\n",
    "               'num_leaves': 2**4,\n",
    "               'verbose':0, \n",
    "               'seed':123\n",
    "              }\n",
    "\n",
    "for train_idx, val_idx in splits:\n",
    "    X_tr, y_tr = np.asarray(train)[train_idx, :], y_gr[train_idx]\n",
    "    X_val, y_val = np.asarray(train)[val_idx, :], y_gr[val_idx]\n",
    "    \n",
    "    model_lgb = lgb.train(lgb_params, lgb.Dataset(X_tr, label=y_tr), 500,\\\n",
    "                           valid_sets=lgb.Dataset(X_val, label=y_val), early_stopping_rounds=30)\n",
    "    pred_lgb = model_lgb.predict(X_val)\n",
    "    val_pred.append(pred_lgb)\n",
    "    val_y.append(y_val)\n",
    "    \n",
    "    val_acc.append(accuracy_score(y_val, np.argmax(pred_lgb, axis=1)))\n",
    "\n",
    "#pred_lgb = pd.DataFrame(pred_lgb, index=np.where(np.mean(adv_val, axis=0)>0.3))\n",
    "#val_pred = pd.concat([val_pred, pred_lgb], axis=0)\n",
    "\n",
    "    clf.append(model_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp = np.zeros(train.shape[1])\n",
    "for model in clf:\n",
    "    feature_imp+=model.feature_importance(importance_type='gain')\n",
    "\n",
    "pd.DataFrame(feature_imp/4, index=data_col).sort_values(by=0, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reserve = X_train.copy()\n",
    "X_test_reserve = X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reserve.to_csv('./rotated_train.csv')\n",
    "X_test_reserve.to_csv('./rotated_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_eng(df):\n",
    "    data = pd.DataFrame()\n",
    "\n",
    "    df['total_acce'] = (df['linear_acceleration_X']**2 + df['linear_acceleration_Y']**2 + df['linear_acceleration_Z']**2)**0.5\n",
    "    #df['total_rotated'] = (df['rotated_acceleration_X']**2 + df['rotated_acceleration_Y']**2 + df['rotated_acceleration_Z']**2)**0.5\n",
    "    #df['total_ang_cos'] = (df['cos_angular_velocity_X']**2 + df['cos_angular_velocity_Y']**2 + df['cos_angular_velocity_Z']**2)**0.5\n",
    "    \n",
    "    df = df.drop(columns=['euler_X'], axis=0)\n",
    "    df = df.drop(columns=['euler_Y'], axis=0)\n",
    "    df = df.drop(columns=['euler_Z'], axis=0)\n",
    "    #df['total_angu'] = (df['angular_velocity_X']**2 + df['angular_velocity_Y']**2 + df['angular_velocity_Z']**2)**0.5\n",
    "    \n",
    "    #df['total_eule'] = (df['euler_X']**2 + df['euler_Y']**2 + df['euler_Z']**2)**0.5\n",
    "    #df['total_xyz'] = (df['orientation_X']**2 + df['orientation_Y']**2 + df['orientation_Z']**2)**0.5\n",
    "    #df['total_acc/vel'] = df['total_acce']/df['total_angu']\n",
    "    \n",
    "    df_columns = df.columns[7:]\n",
    "    for col in tqdm(df_columns):\n",
    "        data[col + '_mean'] = df.groupby(['series_id'])[col].mean()\n",
    "        data[col + '_median'] = df.groupby(['series_id'])[col].median()\n",
    "        data[col + '_max'] = df.groupby(['series_id'])[col].max()\n",
    "        data[col + '_min'] = df.groupby(['series_id'])[col].min()\n",
    "        data[col + '_std'] = df.groupby(['series_id'])[col].std()\n",
    "        data[col + '_range'] = data[col + '_max'] - data[col + '_min']\n",
    "        data[col + '_maxtoMin'] = data[col + '_max'] / data[col + '_min']\n",
    "        data[col + '_mean_abs_chg'] = df.groupby(['series_id'])[col].apply(lambda x: np.mean(np.abs(np.diff(x))))\n",
    "        data[col + '_mean_change_of_abs_change'] = df.groupby('series_id')[col].apply(mean_change_of_abs_change)\n",
    "        data[col + '_abs_max'] = df.groupby(['series_id'])[col].apply(lambda x: np.max(np.abs(x)))\n",
    "        data[col + '_abs_min'] = df.groupby(['series_id'])[col].apply(lambda x: np.min(np.abs(x)))\n",
    "        data[col + '_abs_avg'] = (data[col + '_abs_min'] + data[col + '_abs_max'])/2\n",
    "        \n",
    "        \n",
    "    #data['corr_linZangX'] = np.correlate(np.abs(tmp_df[:, 0]), np.abs(tmp_df[:, 1]))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = feat_eng(X_train)\n",
    "X_test = feat_eng(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.concatenate((np.zeros(len(X_train)), np.ones(len(X_test))), axis=0)\n",
    "X = np.concatenate((X_train, X_test), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SPLITS=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "splits = list(StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=2019).split(X, y))\n",
    "\n",
    "clf_2 = []\n",
    "val_roc = []\n",
    "val_pred = pd.DataFrame()\n",
    "\n",
    "lgb_params = {\n",
    "               'feature_fraction': 0.8,\n",
    "               'metric': 'binary_logloss',\n",
    "               'nthread':8, \n",
    "               'learning_rate': 0.1, \n",
    "               'objective': 'binary',\n",
    "               #'num_class': class_num,\n",
    "               'num_leaves': 2**4,\n",
    "               'verbose':0, \n",
    "               'seed':123\n",
    "              }\n",
    "\n",
    "\n",
    "for train_idx, val_idx in splits:\n",
    "    X_tr, y_tr = X[train_idx, :], y[train_idx]\n",
    "    X_val, y_val = X[val_idx, :], y[val_idx]\n",
    " \n",
    "    model_lgb = lgb.train(lgb_params, lgb.Dataset(X_tr, label=y_tr), 500,\\\n",
    "                           valid_sets=lgb.Dataset(X_val, label=y_val), early_stopping_rounds=30)\n",
    "    pred_lgb = model_lgb.predict(X_val)\n",
    "    \n",
    "    val_roc.append(roc_auc_score(y_val, (pred_lgb>0.5).astype(int)))\n",
    "    \n",
    "    pred_lgb = pd.DataFrame(pred_lgb, index=val_idx)\n",
    "    val_pred = pd.concat([val_pred, pred_lgb], axis=0)\n",
    "    \n",
    "    clf_2.append(model_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp = np.zeros(X.shape[1])\n",
    "for model in clf_2:\n",
    "    feature_imp+=model.feature_importance(importance_type='gain')\n",
    "\n",
    "pd.DataFrame(feature_imp, index=X_train.columns).sort_values(by=0, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "splits = list(StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=2019).split(X_train, y_id))\n",
    "\n",
    "clf_3 = []\n",
    "val_acc = []\n",
    "val_pred = pd.DataFrame()\n",
    "\n",
    "lgb_params = {\n",
    "               'feature_fraction': 0.9,\n",
    "               'metric': 'multi_logloss',\n",
    "               'nthread':8, \n",
    "               'learning_rate': 0.1, \n",
    "               'objective': 'multiclass',\n",
    "               'num_class': class_num,\n",
    "               'num_leaves': 2**5,\n",
    "               'verbose':0, \n",
    "               'seed':123\n",
    "              }\n",
    "\n",
    "for train_idx, val_idx in splits:\n",
    "    X_tr, y_tr = X_train.iloc[train_idx, :], y_id[train_idx]\n",
    "    X_val, y_val = X_train.iloc[val_idx, :], y_id[val_idx]\n",
    "    \n",
    "    model_lgb = lgb.train(lgb_params, lgb.Dataset(X_tr, label=y_tr), 500,\\\n",
    "                           valid_sets=lgb.Dataset(X_val, label=y_val), early_stopping_rounds=30)\n",
    "    pred_lgb = model_lgb.predict(X_val)\n",
    "\n",
    "    val_acc.append(accuracy_score(y_val, np.argmax(pred_lgb, axis=1)))\n",
    "\n",
    "#pred_lgb = pd.DataFrame(pred_lgb, index=np.where(np.mean(adv_val, axis=0)>0.3))\n",
    "#val_pred = pd.concat([val_pred, pred_lgb], axis=0)\n",
    "\n",
    "clf_3.append(model_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp = np.zeros(X_train.shape[1])\n",
    "for model in clf_3:\n",
    "    feature_imp+=model.feature_importance(importance_type='gain')\n",
    "\n",
    "pd.DataFrame(feature_imp, index=X_train.columns).sort_values(by=0, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X_train['angular_velocity_Y-angular_velocity_Y-1_mean_abs_chg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = []\n",
    "for model in clf:\n",
    "    pred_test = model.predict(test)\n",
    "    test_pred.append(pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = (test_pred[0]+test_pred[1]+test_pred[2]+test_pred[3])/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pr = pd.concat([pd.Series(np.argmax(test_pred, axis=1)), pd.Series(np.max(test_pred, axis=1))], axis=1)\n",
    "test_pr.columns = ['group_id', 'prob']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr_sr = pd.DataFrame()\n",
    "for i in range(73):\n",
    "    gr = pd.DataFrame({'group_id':[i], 'surface':[y_train[y_train['group_id']==i]['surface'].iloc[0]]})\n",
    "    gr_sr = pd.concat([gr_sr, gr], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pr = test_pr.merge(gr_sr, how='left', on='group_id', sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gr_idx = test_pr[test_pr['prob']<=0.7].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.loc[test_gr_idx, :].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pr[test_pr['prob']>0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1699-979"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = []\n",
    "\n",
    "for model in clf_3:\n",
    "    preds_test.append(model.predict(X_test.loc[test_gr_idx, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = np.argmax(np.mean(preds_test, axis=0), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_surface = []\n",
    "for i in preds_test:\n",
    "    test_surface.append(id_to_target[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_surface = np.asarray(test_surface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = pd.DataFrame(test_surface, index=test_gr_idx, columns=['surface'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = pd.concat([pd.DataFrame(test_pr[test_pr['prob']>0.7]['surface']), preds_test], axis=0).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../input/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['surface'] = preds_test['surface']\n",
    "submission.to_csv('../output/submission_9.csv', index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['linear_acceleration_X', 'linear_acceleration_Y', 'linear_acceleration_Z', 'angular_velocity_X', 'angular_velocity_Y', 'angular_velocity_Z']\n",
    "df_peak = pd.DataFrame()\n",
    "\n",
    "for i in tqdm(range(0, len(X_train), 128)):\n",
    "    X_tr = X_train.iloc[i:i+128, :]\n",
    "    df_cols = pd.DataFrame()\n",
    "    for col in cols:\n",
    "        peaks = signal.find_peaks(X_tr[col], rel_height=1.0)[0]\n",
    "        peak_num = len(peaks)\n",
    "        peak_width = signal.peak_widths(X_tr[col], peaks, rel_height=1.0)[0]\n",
    "        peak_pro = signal.peak_prominences(X_tr[col], peaks)[0]\n",
    "        \n",
    "        if peak_num != 0:\n",
    "            peak_df = pd.DataFrame({\n",
    "                             col+'_peak_num':[peak_num], \n",
    "                             col+'_peak_width_max':[np.max(peak_width)],\n",
    "                             col+'_peak_width_min':[np.min(peak_width)],\n",
    "                             col+'_peak_width_mean':[np.mean(peak_width)],\n",
    "                             col+'_peak_pro_max':[np.max(peak_pro)],\n",
    "                             col+'_peak_pro_min':[np.min(peak_pro)],\n",
    "                             col+'_peak_pro_mean':[np.mean(peak_pro)]\n",
    "                            }, index=[i//128])\n",
    "        else:\n",
    "            peak_df = pd.DataFrame({\n",
    "                             col+'_peak_num':[peak_num], \n",
    "                             col+'_peak_width_max':[0],\n",
    "                             col+'_peak_width_min':[0],\n",
    "                             col+'_peak_width_mean':[0],\n",
    "                             col+'_peak_pro_max':[0],\n",
    "                             col+'_peak_pro_min':[0],\n",
    "                             col+'_peak_pro_mean':[0]\n",
    "                            }, index=[i//128])\n",
    "            \n",
    "        df_cols = pd.concat([df_cols, peak_df], axis=1)\n",
    "    df_peak = pd.concat([df_peak, df_cols], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['linear_acceleration_X', 'linear_acceleration_Y', 'linear_acceleration_Z', 'angular_velocity_X', 'angular_velocity_Y', 'angular_velocity_Z']\n",
    "df_peak_te = pd.DataFrame()\n",
    "\n",
    "for i in tqdm(range(0, len(X_test), 128)):\n",
    "    X_tr = X_test.iloc[i:i+128, :]\n",
    "    df_cols = pd.DataFrame()\n",
    "    for col in cols:\n",
    "        peaks = signal.find_peaks(X_tr[col], rel_height=1.0)[0]\n",
    "        peak_num = len(peaks)\n",
    "        peak_width = signal.peak_widths(X_tr[col], peaks, rel_height=1.0)[0]\n",
    "        peak_pro = signal.peak_prominences(X_tr[col], peaks)[0]\n",
    "        \n",
    "        if peak_num != 0:\n",
    "            peak_df = pd.DataFrame({\n",
    "                             col+'_peak_num':[peak_num], \n",
    "                             col+'_peak_width_max':[np.max(peak_width)],\n",
    "                             col+'_peak_width_min':[np.min(peak_width)],\n",
    "                             col+'_peak_width_mean':[np.mean(peak_width)],\n",
    "                             col+'_peak_pro_max':[np.max(peak_pro)],\n",
    "                             col+'_peak_pro_min':[np.min(peak_pro)],\n",
    "                             col+'_peak_pro_mean':[np.mean(peak_pro)]\n",
    "                            }, index=[i//128])\n",
    "        else:\n",
    "            peak_df = pd.DataFrame({\n",
    "                             col+'_peak_num':[peak_num], \n",
    "                             col+'_peak_width_max':[0],\n",
    "                             col+'_peak_width_min':[0],\n",
    "                             col+'_peak_width_mean':[0],\n",
    "                             col+'_peak_pro_max':[0],\n",
    "                             col+'_peak_pro_min':[0],\n",
    "                             col+'_peak_pro_mean':[0]\n",
    "                            }, index=[i//128])\n",
    "            \n",
    "        df_cols = pd.concat([df_cols, peak_df], axis=1)\n",
    "    df_peak_te = pd.concat([df_peak_te, df_cols], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_peak.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_eng(df):\n",
    "    data = pd.DataFrame()\n",
    "    #df['linear_acceleration_Z'] += 9.80665\n",
    "    #df['eulerX-Z'] = df['euler_X']-df['euler_Z']\n",
    "    df['total_acce'] = (df['linear_acceleration_X']**2 + df['linear_acceleration_Y']**2 + df['linear_acceleration_Z']**2)**0.5\n",
    "#df['total_rotated'] = (df['rotated_acceleration_X']**2 + df['rotated_acceleration_Y']**2 + df['rotated_acceleration_Z']**2)**0.5\n",
    "    #df['total_ang_cos'] = (df['angular_velocity_X_cos']**2 + df['angular_velocity_Y_cos']**2 + df['angular_velocity_Z_cos']**2)**0.5\n",
    "    \n",
    "    tmp_df = pd.concat([df['linear_acceleration_Z'], df['angular_velocity_X']], axis=1)\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    tmp_df = scaler.fit_transform(tmp_df)\n",
    "    \n",
    "    #df['total_angu'] = (df['angular_velocity_X']**2 + df['angular_velocity_Y']**2 + df['angular_velocity_Z']**2)**0.5\n",
    "    \n",
    "    #df['total_eule'] = (df['euler_X']**2 + df['euler_Y']**2 + df['euler_Z']**2)**0.5\n",
    "    #df['total_xyz'] = (df['orientation_X']**2 + df['orientation_Y']**2 + df['orientation_Z']**2)**0.5\n",
    "    #df['total_acc/vel'] = df['total_acce']/df['total_angu']\n",
    "    \n",
    "    df_columns = df.columns[3:]\n",
    "    for col in tqdm(df_columns):\n",
    "        data[col + '_mean'] = df.groupby(['series_id'])[col].mean()\n",
    "        data[col + '_median'] = df.groupby(['series_id'])[col].median()\n",
    "        data[col + '_max'] = df.groupby(['series_id'])[col].max()\n",
    "        data[col + '_min'] = df.groupby(['series_id'])[col].min()\n",
    "        data[col + '_std'] = df.groupby(['series_id'])[col].std()\n",
    "        data[col + '_range'] = data[col + '_max'] - data[col + '_min']\n",
    "        data[col + '_maxtoMin'] = data[col + '_max'] / data[col + '_min']\n",
    "        data[col + '_mean_abs_chg'] = df.groupby(['series_id'])[col].apply(lambda x: np.mean(np.abs(np.diff(x))))\n",
    "        data[col + '_mean_change_of_abs_change'] = df.groupby('series_id')[col].apply(mean_change_of_abs_change)\n",
    "        data[col + '_abs_max'] = df.groupby(['series_id'])[col].apply(lambda x: np.max(np.abs(x)))\n",
    "        data[col + '_abs_min'] = df.groupby(['series_id'])[col].apply(lambda x: np.min(np.abs(x)))\n",
    "        data[col + '_abs_avg'] = (data[col + '_abs_min'] + data[col + '_abs_max'])/2\n",
    "        \n",
    "        \n",
    "    #data['corr_linZangX'] = np.correlate(np.abs(tmp_df[:, 0]), np.abs(tmp_df[:, 1]))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train = feat_eng(X_train)\n",
    "X_test = feat_eng(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_peak.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_peak_te.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_train, df_peak], axis=1)\n",
    "X_test = pd.concat([X_test, df_peak_te], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_col = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in [X_train, X_test]:\n",
    "    data.fillna(0,inplace=True)\n",
    "    data.replace(-np.inf,0,inplace=True)\n",
    "    data.replace(np.inf,0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SPLITS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def auroc(y_true, y_pred):\n",
    "    return tf.py_function(roc_auc_score, (y_true, y_pred), tf.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.concatenate((np.zeros(len(X_train)), np.ones(len(X_test))), axis=0)\n",
    "X = np.concatenate((X_train, X_test), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = list(StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=2019).split(X, y))\n",
    "\n",
    "clf_2 = []\n",
    "val_roc = []\n",
    "val_pred = pd.DataFrame()\n",
    "\n",
    "lgb_params = {\n",
    "               'feature_fraction': 0.8,\n",
    "               'metric': 'binary_logloss',\n",
    "               'nthread':8, \n",
    "               'learning_rate': 0.1, \n",
    "               'objective': 'binary',\n",
    "               #'num_class': class_num,\n",
    "               'num_leaves': 2**4,\n",
    "               'verbose':0, \n",
    "               'seed':123\n",
    "              }\n",
    "\n",
    "\n",
    "for train_idx, val_idx in splits:\n",
    "    X_tr, y_tr = X[train_idx, :], y[train_idx]\n",
    "    X_val, y_val = X[val_idx, :], y[val_idx]\n",
    " \n",
    "    model_lgb = lgb.train(lgb_params, lgb.Dataset(X_tr, label=y_tr), 500,\\\n",
    "                           valid_sets=lgb.Dataset(X_val, label=y_val), early_stopping_rounds=30)\n",
    "    pred_lgb = model_lgb.predict(X_val)\n",
    "    \n",
    "    val_roc.append(roc_auc_score(y_val, (pred_lgb>0.5).astype(int)))\n",
    "    \n",
    "    pred_lgb = pd.DataFrame(pred_lgb, index=val_idx)\n",
    "    val_pred = pd.concat([val_pred, pred_lgb], axis=0)\n",
    "    \n",
    "    clf_2.append(model_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp = np.zeros(X_train.shape[1])\n",
    "for model in clf_2:\n",
    "    feature_imp+=model.feature_importance(importance_type='gain')\n",
    "\n",
    "pd.DataFrame(feature_imp/5, index=data_col).sort_values(by=0, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_val = []\n",
    "for model in clf_2:\n",
    "    adv_val.append(model.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.sort(np.mean(adv_val, axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = []\n",
    "\n",
    "for model in clf:\n",
    "    preds_test.append(model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = np.argmax(np.mean(preds_test, axis=0), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_surface = []\n",
    "for i in preds_test:\n",
    "    test_surface.append(id_to_target[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_surface = np.asarray(test_surface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../input/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['surface'] = test_surface\n",
    "submission.to_csv('../output/submission_6.csv', index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
